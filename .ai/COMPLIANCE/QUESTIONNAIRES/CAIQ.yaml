# ===========================================
# CAIQ (Consensus Assessment Initiative Questionnaire)
# ===========================================
# Pre-written answers for cloud security assessments.
# Based on CSA CAIQ v4 format with AI governance extensions.
# ===========================================

metadata:
  version: "1.0"
  last_updated: "2025-01-01"
  framework: "CSA CAIQ v4"
  owner: "Security Team"

CAIQ:
  # ===========================================
  # AIS - Application & Interface Security
  # ===========================================
  - id: AIS-01
    category: "Application & Interface Security"
    question: "Do you use industry standards to build and maintain software?"
    answer: |
      Yes. Our development follows industry standards:
      - Python 3.10+ with strict type hints
      - PEP 8 style enforcement via Ruff
      - Security scanning with Bandit (OWASP)
      - Dependency vulnerability scanning with pip-audit
      - 85% minimum test coverage requirement
    evidence:
      - pyproject.toml
      - .github/workflows/ci.yml
    status: "Implemented"

  - id: AIS-02
    category: "Application & Interface Security"
    question: "Do you perform security testing (SAST/DAST) on applications?"
    answer: |
      Yes. Security testing is automated in CI:
      - SAST: Bandit static analysis on every PR
      - Dependency scanning: pip-audit and Safety
      - Security scans block merge on HIGH/CRITICAL findings
      - Weekly scheduled scans in addition to PR scans
    evidence:
      - .github/workflows/security.yml
    status: "Implemented"

  # ===========================================
  # CEK - Cryptography & Key Management
  # ===========================================
  - id: CEK-01
    category: "Cryptography & Key Management"
    question: "Do you encrypt data in transit?"
    answer: |
      Yes. All data in transit is encrypted:
      - HTTPS required for all API communications
      - TLS 1.2+ enforced for external connections
      - GitHub Actions uses encrypted runners
    evidence:
      - .github/workflows/ci.yml
    status: "Implemented"

  - id: CEK-02
    category: "Cryptography & Key Management"
    question: "How do you manage secrets and API keys?"
    answer: |
      Secrets are managed securely:
      - GitHub Secrets for CI/CD credentials
      - No secrets committed to repository (detected by pre-commit)
      - Environment variables for runtime configuration
      - .env files excluded from version control
    evidence:
      - .gitignore
      - .env.example
    status: "Implemented"

  # ===========================================
  # CCC - Change Control & Configuration
  # ===========================================
  - id: CCC-01
    category: "Change Control & Configuration"
    question: "Do you have a change management process?"
    answer: |
      Yes. All changes follow a formal process:
      1. Developer creates feature branch
      2. Changes submitted via pull request
      3. Automated CI validates changes (lint, tests, security)
      4. AI reviews code and classifies risk
      5. Code owners must approve
      6. Only LOW risk changes may auto-merge
      7. MEDIUM/HIGH/CRITICAL require human approval
    evidence:
      - .github/workflows/ci.yml
      - .github/workflows/ai-review.yml
      - .ai/AUTO_MERGE_POLICY.yaml
    status: "Implemented"

  - id: CCC-02
    category: "Change Control & Configuration"
    question: "Do you track and log all changes?"
    answer: |
      Yes. Complete audit trail maintained:
      - Git history for all code changes
      - PR comments with AI review results
      - SQLite database for metrics and events
      - YAML logs for compliance evidence
    evidence:
      - .ai/ai_metrics.db
      - .ai/COMPLIANCE/SOC2_EVIDENCE_LOG.yaml
    status: "Implemented"

  # ===========================================
  # DSP - Data Security & Privacy
  # ===========================================
  - id: DSP-01
    category: "Data Security & Privacy"
    question: "How do you classify and protect sensitive data?"
    answer: |
      Data classification is enforced through:
      - Risk classification of all code changes
      - Blocked file patterns for sensitive paths
      - CODEOWNERS for access control
      - Security scans detect hardcoded secrets
    evidence:
      - .ai/AUTO_MERGE_POLICY.yaml
      - .github/CODEOWNERS
    status: "Implemented"

  # ===========================================
  # GRM - Governance & Risk Management
  # ===========================================
  - id: GRM-01
    category: "Governance & Risk Management"
    question: "Do you have a risk management program?"
    answer: |
      Yes. We maintain a formal risk management program:
      - ISO 27001-aligned risk register
      - 7 identified and assessed risks
      - Quarterly risk reviews
      - Risk scoring matrix (Likelihood x Impact)
      - Treatment plans for each risk
    evidence:
      - .ai/COMPLIANCE/ISO_RISK_REGISTER.yaml
      - reports/ISO_Risk_Register_Report.md
    status: "Implemented"

  - id: GRM-02
    category: "Governance & Risk Management"
    question: "Do you align with security frameworks?"
    answer: |
      Yes. We align with multiple frameworks:
      - SOC-2 Type II (evidence collection active)
      - ISO 27001:2022 (controls mapped)
      - Automated compliance scoring
      - Evidence packages for auditors
    evidence:
      - .ai/COMPLIANCE/SOC2_MAPPING.yaml
      - .ai/COMPLIANCE/ISO27001_MAPPING.yaml
    status: "Implemented"

  # ===========================================
  # AIG - AI Governance (Custom Extension)
  # ===========================================
  - id: AIG-01
    category: "AI Governance"
    question: "Do you use AI in your development process?"
    answer: |
      Yes. AI is used with strict governance:
      - AI-assisted code review on all PRs
      - Risk classification by AI (LOW/MEDIUM/HIGH/CRITICAL)
      - All AI interactions logged and auditable
      - Human oversight required for significant decisions
      - AI cannot approve its own changes
    evidence:
      - .ai/CLAUDE_RULES.md
      - .github/workflows/ai-review.yml
    status: "Implemented"

  - id: AIG-02
    category: "AI Governance"
    question: "What guardrails exist for AI-generated code?"
    answer: |
      Multiple guardrails ensure AI safety:
      - Mandatory human review for MEDIUM+ risk changes
      - AI confidence threshold (0.85) for auto-merge
      - Blocked file patterns prevent AI from modifying critical paths
      - All AI suggestions pass same CI gates as human code
      - Fail-open for AI failures (blocks auto-merge, allows human review)
    evidence:
      - .ai/AUTO_MERGE_POLICY.yaml
      - .ai/CLAUDE_RULES.md
    status: "Implemented"

  - id: AIG-03
    category: "AI Governance"
    question: "How do you ensure AI decisions are explainable?"
    answer: |
      AI decisions are transparent:
      - Risk classification includes reasoning in PR comments
      - All AI reviews posted as PR comments
      - Metrics database tracks AI confidence scores
      - Executive reports show AI accuracy over time
    evidence:
      - scripts/pr_commenter.py
      - scripts/ai_metrics.py
    status: "Implemented"

  - id: AIG-04
    category: "AI Governance"
    question: "Can AI actions be overridden by humans?"
    answer: |
      Yes. Human override is always available:
      - Humans can approve changes AI rejected
      - Humans can reject changes AI approved
      - Manual merge available when auto-merge blocked
      - Governance rules require human final decision for HIGH/CRITICAL
    evidence:
      - .ai/AUTO_MERGE_POLICY.yaml
      - .ai/CLAUDE_RULES.md
    status: "Implemented"

  # ===========================================
  # IAM - Identity & Access Management
  # ===========================================
  - id: IAM-01
    category: "Identity & Access Management"
    question: "Do you require multi-factor authentication?"
    answer: |
      Yes. MFA is required:
      - GitHub organization requires MFA for all members
      - SSO integration available for enterprise
      - API access uses scoped tokens
    evidence:
      - Organization settings (external)
    status: "Implemented"

  - id: IAM-02
    category: "Identity & Access Management"
    question: "Do you follow least-privilege access principles?"
    answer: |
      Yes. Access follows least-privilege:
      - Role-based access via GitHub teams
      - CODEOWNERS restricts who can modify sensitive files
      - Branch protection prevents direct pushes
      - Separate environments for dev/staging/prod
    evidence:
      - .github/CODEOWNERS
    status: "Implemented"

  # ===========================================
  # IVS - Infrastructure & Virtualization
  # ===========================================
  - id: IVS-01
    category: "Infrastructure & Virtualization"
    question: "Do you use secure CI/CD infrastructure?"
    answer: |
      Yes. CI/CD runs on secure infrastructure:
      - GitHub Actions hosted runners
      - Ephemeral execution environments
      - No persistent state between runs
      - Secrets injected at runtime only
    evidence:
      - .github/workflows/ci.yml
    status: "Implemented"

  # ===========================================
  # SEF - Security Incident Management
  # ===========================================
  - id: SEF-01
    category: "Security Incident Management"
    question: "Do you have incident response procedures?"
    answer: |
      Yes. Incident response is automated where possible:
      - CI failures trigger immediate Slack notifications
      - Self-healing agent attempts auto-remediation
      - Mean time to detect: < 1 minute
      - Mean time to respond: < 5 minutes (automated)
      - Human escalation for complex issues
    evidence:
      - scripts/pr_self_heal.py
      - scripts/slack_notifier.py
    status: "Implemented"

  - id: SEF-02
    category: "Security Incident Management"
    question: "Do you log security events?"
    answer: |
      Yes. Security events are logged:
      - All CI/CD events in metrics database
      - Compliance evidence in YAML logs
      - GitHub audit log integration
      - Retention: 365 days minimum
    evidence:
      - .ai/ai_metrics.db
      - .ai/COMPLIANCE/SOC2_EVIDENCE_LOG.yaml
    status: "Implemented"
